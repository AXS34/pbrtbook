\section{控制舍入误差}\label{sec:控制舍入误差}

\begin{remark}
    本节含有高级内容，第一次阅读时可以跳过。
\end{remark}

到目前为止，我们都是根据基于实数的理想化算术运算
纯粹地讨论光线——形状相交算法。该方法已经让我们走得很远了，
尽管有个重要事实是计算机只能表示有限的数量，
因此它实际上不能表示所有实数。
计算机用浮点数代替实数，它有固定的存储要求。
然而，因为结果可能无法在特定量的内存中表示，
每执行一次浮点运算就可能引入误差。

该误差的累积对相交测试的精度有些许影响。
首先，它可能造成完全错过有效的相交——
例如，一个精确值是正数的相交处$t$值算成了负的。
而且，算得的光线——形状交点可能在形状实际曲面的上面或下面。
这导致一个问题：当从算得的交点开始为阴影射线和反射光线追踪新光线时，
若射线端点在实际曲面之下，我们可能求得一次与曲面错误的再相交。
反之，若端点在曲面上面离得太远，阴影和反射可能会脱钩（见\reffig{3.39}）。
\begin{figure}[htbp]
    \centering\input{Pictures/chap03/Selfintersectioncases.tex}
    \caption{可能在图像中造成可见错误的舍入误差问题几何设置。
        左边的入射光线与曲面相交。在左图中，算得的交点（黑圆圈）略低于曲面
        且阴影射线端点过低的“epsilon”偏移可能导致错误的自相交，
        因为阴影射线端点（白圆圈）仍在曲面之下；因此错误地认定光源被遮挡了。
        右图中，太高的“epsilon”导致错过了有效相交，
        因为射线端点通过了遮挡面。}
    \label{fig:3.39}
\end{figure}

在光线追踪中解决该问题的典型实践是将生成的射线偏移固定的“射线epsilon”值
\sidenote{译者注：epsilon即希腊字母$\epsilon$。}，
忽略沿射线$\bm p+t\bm d$比某个$t_{\min}$还近的任何相交。
\reffig{3.40}展示了为什么该方法需要很高的$t_{\min}$值才能高效工作：
如果生成的射线相对于曲面非常倾斜，
则在离射线很远处可能会发生错误的射线相交。
不幸的是，大的$t_{\min}$值会造成射线端点相对远离原始交点，
这又反过来造成错过附近的有效相交，导致阴影和反射丢失细节。
\begin{figure}[htbp]
    \centering\input{Pictures/chap03/Selfintersectionobliqueray.tex}
    \caption{如果算得的交点（实心圆）低于曲面且生成的射线是斜的，
        在与射线端点有一定距离的地方可能会发生错误的再相交（空心圆）。
        如果用沿射线的最小$t$值消除附近的相交，
        需要相对大的$t_{\min}$才能处理好倾斜射线。}
    \label{fig:3.40}
\end{figure}

本节中，我们将介绍浮点算术基本思想并描述分析浮点计算误差的技术。
然后我们将这些方法用于本章之前介绍的光线——形状算法
并展示怎样计算带有有界误差的光线交点。
这将允许我们保守地定位射线端点，这样就永远不会求得错误的自相交，
而又保留了与实际交点极其接近的射线端点使得错误脱靶被最小化。
反过来也不需要额外的“射线epsilon”值。

\subsection{浮点算术}\label{sub:浮点算术}
计算必须在容纳于有限量内存的数字的有限表示上执行；
计算机上无法表示实数的无限集合。
一种这样的有限表示是定点，例如给定一个16位整数，
有人可能通过除以256将其映射为正实数。
这允许我们表示值之间具有相等间距$\displaystyle\frac{1}{256}$的
范围$\displaystyle\left[0,\frac{65535}{256}\right]=\left[0,255+\frac{255}{256}\right]$。
\keyindex{定点数}{fixed-point number}{}可以用整数算术运算高效实现
（该特性使其在早期不支持浮点计算的个人计算机上很流行），
但是它们受制于许多缺点：其中，它们能表示的最大数字是受限的，
且不能精确表示非常小的接近于零的数。

计算机上实数的另一种表示是\keyindex{浮点数}{floating-point number}{}。
它用\keyindex{符号}{sign}{}、\keyindex{有效数字}{significand}{}\footnote{单词“\protect\keyindex{尾数}{mantissa}{}”
    常用来代替“有效数字”，但浮点纯粹主义者注意到“尾数”在对数上下文中
    有不同含义而因此更偏爱“有效数字”。这里我们遵循该用法。}和\keyindex{指数}{exponent}{}表示数字：
本质上和\keyindex{科学计数法}{scientific notation}{}相同但用固定数量的数字表示有效数字和指数。
（下文中，我们将只讨论以2为底的数字。）
这种表示能够用固定数量的存储对极大范围的数字进行表示和执行计算。

用浮点算术的程序员通常知道浮点是不精确的；
有时这种看法导致了浮点算术是不可预测的观念。
本节中我们将看到浮点算术有精心设计的基础反而
能计算特定计算中引入误差的保守边界。
对于光线追踪计算，该误差常意外地小。

现代CPU和GPU几乎都基于电气与电子工程师协会
\sidenote{译者注：即Institute of Electrical and Electronics Engineers (IEEE)，
    是电气工程与电子工程以及相关学科的专业协会，成立于1963年1月，总部在美国纽约。
    其范围已经扩展到电气、电子、通信、计算机工程、计算机科学与信息技术等诸多领域，
    是世界上最大的技术专业组织。}
颁布的标准\parencite*{10.1109/IEEESTD.1985.82928,10.1109/IEEESTD.2008.4610935}实现浮点算术模型。
（今后我们说的浮点特指IEEE 754规定的32位浮点数。）
IEEE 754技术标准规定了内存中浮点数的格式以及
精度和浮点计算舍入的特定规则；
正是这些规则使得能对给定浮点值中出现的误差进行严格推导。

\subsubsection*{浮点表示}
IEEE标准规定32位浮点用1位符号、8位指数和23位有效数字表示。
用了8位的指数$e$范围为从0到255；
实际用的指数$e_{\mathrm{b}}$是通过偏置$e$算得的：
\begin{align*}
    e_{\mathrm{b}}=e-127\, .
\end{align*}

当存储\keyindex{规范化的}{normalized}{}浮点值时有效数字实际有24位精度。
当有效数字和指数表示规范化的数字时，有效数字中没有前导零。
在\keyindex{二进制}{binary}{}中，这意味着有效数字开头的数字必须是一；
反过来，没必要显式存储该值。
因此，隐式前导的1位和编码有效数字小数部分的23位给出了总共24位的精度。

给定符号$s=\pm 1$、有效数字$m$和指数$e$，相应的浮点值为
\begin{align*}
    s\times 1.m\times2^{e-127}\, .
\end{align*}

例如，浮点数6.5可以通过规范化的有效数字写作$1.101_2\times2^2$，
其中下标2表示以2为底的值\sidenote{译者注：即二进制。}
（如果非整数的二进制数不够直观，可以注意
小数点右边第一个数表示$\displaystyle 2^{-1}=1/2$，以此类推）。
因此，我们有
\begin{align*}
    (1\times2^0+1\times2^{-1}+0\times2^{-2}+1\times2^{-3})\times2^2=1.625\times2^2=6.5\, .
\end{align*}
$e_{\mathrm{b}}=2$，所以$e=129=10000001_2$且$m=10100000000000000000000_2$。

浮点在内存中的布局是符号位在32位值的最高位
（负号用一位编码），然后是指数和有效数字。
因此，对于值6.5其内存中的二进制表示是
\begin{align*}
    0\ 10000001\ 10100000000000000000000=40\mathrm{d}00000_{16}\, .
\end{align*}

同样，浮点值1.0有$m=0\ldots0_2$和$e_{\mathrm{b}}=0$，所以$e=127=01111111_2$，它的二进制表示为
\begin{align*}
    0\ 01111111\ 00000000000000000000000=3\mathrm{f}800000_{16}\, .
\end{align*}

该\keyindex{十六进制}{hexadecimal}{}值值得记住，因为调试时它常出现于内存转储。

该表示隐含了整个范围内两个相邻的二的幂次之间
可表示的浮点数之间的间隔是均匀的（它对应于有效数字位增一）。
在范围$[2^e,2^{e+1})$内，间隔为
\begin{align}\label{eq:3.6}
    2^{e-23}\, .
\end{align}
因此对1和2之间的浮点数，$e=0$，
浮点值间的间隔为$2^{-23}\approx1.19209\times10^{-7}$。
该间隔也称为\keyindex{最后一位上的单位值}{unit in last place}{}(ulp)\sidenote{译者注：也叫“最小精度单位”。}的大小；
注意一个ulp的大小由相应浮点值决定——更大的数的ulp比更小的数的ulp相对更大。

按我们目前描述的表示是不可能恰好将零表示为浮点数的。
这事显然不可接受，所以最小指数$e=0$，
或说$e_{\mathrm{b}}=-127$，被留出来特殊对待。
对于该指数，浮点值解释为有效数字中没有隐式前导一位，
这意味全零位的有效数字会得到
\begin{align*}
    s\times0.0\ldots0_2\times2^{-127}=0\, .
\end{align*}

去掉有效数字前导一位也能表示\sidenote{译者注：我完善了这两个式子。}\keyindex{非规范化的}{denormalized}{}数：
如果总是出现前导一，则最小的32位浮点是
\begin{align*}
    1.{\underbrace{0\ldots0}_{\text{23个0}}}\ _2\times2^{-127}\approx5.8774718\times10^{-39}\, .
\end{align*}
没有前导一位，最小值是
\begin{align*}
    0.\underbrace{0\ldots0}_{\text{22个0}}1_2\times2^{-126}=2^{-23}\times2^{-126}\approx1.4012985\times10^{-45}\, .
\end{align*}

有了一些表示这些小值的能力可以避免需要将非常小的数舍入为零。

注意该表示同时有“正”和“负”零值。
该细节对程序员大多是透明的。
例如，标准保证了比较{\ttfamily -0.0 == 0.0}为真，
即使这两值在内存中的表示不同。

最大指数，$e=255$，也保留作特殊对待。
因此，可以表示的最大规范化浮点值有$e=254$（或$e_{\mathrm{b}}=127$）且约为\sidenote{译者注：我完善了该式。}
\begin{align*}
    1.{\underbrace{1\ldots1}_{\text{23个1}}}\ _2\times2^{127}=(2-2^{-23})\times2^{127}\approx3.402823\times10^{38}\, .
\end{align*}

对于$e=255$，若有效数字位全是零，则该值依据符号位对应正或负无穷。
例如，在浮点中执行像1/0的计算会得到无穷值。
对无穷的算术运算得到无穷。
比较时，正无穷大于任何非无穷值，负无穷类似。

常数\refvar{MaxFloat}{}和\refvar{Infinity}{}分别初始化为可表示的最大和“无穷”浮点值。
我们令其可在单独的常数中获取，这样使用这些值的代码
就不需要用唠叨的C++标准库调用来获取它们的值了。
\begin{lstlisting}
`\initcode{Global Constants}{=}\initnext{GlobalConstants}`
static constexpr `\refvar{Float}{}` `\initvar{MaxFloat}{}` = std::numeric_limits<`\refvar{Float}{}`>::max();
static constexpr `\refvar{Float}{}` `\initvar{Infinity}{}` = std::numeric_limits<`\refvar{Float}{}`>::infinity();
\end{lstlisting}

对于$e=255$，非零有效数字位对应
特殊的NaN值\sidenote{译者注：原文误写为$e_b=255$，已修正。}，
它由诸如取负数平方根或尝试计算0/0的运算得到。
NaN随计算传播：\keyindex{运算对象}{operand}{}之一
为NaN本身的任何算术运算总是返回NaN。
因此，如果NaN出现于一长串计算中，
我们就知道该方式中的某处出错了。
在调试构建中，pbrt有许多\refvar{Assert}{()}语句检查NaN值，
因为我们几乎从不希望它们出现在事件的常规过程中。
任何与NaN值的比较返回假；
因此检查{\ttfamily !(x == x)}用来检查值是否不是数字
\footnote{这是编译器不得对包含浮点值的表达式执行
看似明显且安全的代数简化的少数几个地方之一——
这个特别的比较不得简化为{\ttfamily false}。
启用编译器的“快速数学”或“执行不安全的数学优化”标志
可能会允许执行这些优化。但是错误行为可能引入pbrt中。}。
为了清楚起见，我们用C++标准库函数{\ttfamily std::isnan()}来检查NaN值。

\subsubsection*{实用例程}
对于某些底层运算，能将浮点值解释为其组成位以及将表示浮点值的数位
转换为实际的{\ttfamily float}或{\ttfamily double}很有用。

一个自然的方法是取指向要转换的值的指针并将其强制转换为另一类型：
{\ttfamily\newline\noindent
float f = ...;\newline\noindent
uint32\_t bits = *((uint32\_t *)\&f);\newline
}
然而，现代版本的C++规定将一种{\ttfamily float}指针强制转换为
不同类型{\ttfamily uint32\_t}是非法的
（该限制允许编译器在分析两个指针是否可能指向
同一内存位置时进行更激进的优化，禁止在寄存器中保存值）。

另一常见方法是对两类元素使用{\ttfamily union}，赋予一种类型并按另一种读取：
{\ttfamily\newline\noindent
union FloatBits \{\newline\noindent
\indent float f;\newline\noindent
\indent uint32\_t ui;\newline\noindent
\};\newline\noindent
FloatBits fb;\newline\noindent
fb.f = ...;\newline\noindent
uint32\_t bits = fb.ui;
}

这也是非法的：C++标准说从{\ttfamily union}读取和最后一次赋值时不同的元素是未定义行为。

可以用{\ttfamily memcpy()}将指向源类型的指针复制到指向目标类型的指针来正确执行这些转换。
\begin{lstlisting}
`\initcode{Global Inline Functions}{=}\initnext{GlobalInlineFunctions}`
inline uint32_t `\initvar{FloatToBits}{}`(float f) {
    uint32_t ui;
    memcpy(&ui, &f, sizeof(float));
    return ui;
}
\end{lstlisting}
\begin{lstlisting}
`\refcode{Global Inline Functions}{+=}\lastnext{GlobalInlineFunctions}`
inline float `\initvar{BitsToFloat}{}`(uint32_t ui) {
    float f;
    memcpy(&f, &ui, sizeof(uint32_t));
    return f;
}
\end{lstlisting}

尽管调用函数{\ttfamily memcpy()}以避免这些问题可能看起来太昂贵了，
但实际中好的编译器会将其变为无操作而只是将寄存器或内存中的内容重新解释为另一类型
（pbrt中还有这些函数在{\ttfamily double}和{\ttfamily uint64\_t}之间
转换的类似版本，所以这里就不介绍了）。

这些转换可用于实现函数即把浮点值向上或向下调整到相邻更大或更小的可表示浮点值
\footnote{这些函数等价于{\ttfamily std::nextafter(v, Infinity)}和{\ttfamily std::nextafter(v, -Infinity)}但更加高效，
因为它们不负责处理NaN值或浮点信号异常。}。
它们对我们接下来的代码中需要的某些保守的舍入操作很有用。
多亏浮点在内存中表示的特殊性，这些操作很高效。
\begin{lstlisting}
`\refcode{Global Inline Functions}{+=}\lastnext{GlobalInlineFunctions}`
inline float `\initvar{NextFloatUp}{}`(float v) {
    `\refcode{Handle infinity and negative zero for NextFloatUp()}{}`
    `\refcode{Advance v to next higher float}{}`
}
\end{lstlisting}

有两种重要的特殊情况：如果{\ttfamily v}为正无穷，则该函数就返回没变的{\ttfamily v}。
在继续执行有效数字的代码之前让负零向前跳到正零。
这一步必须显式处理，因为-0.0和0.0的位模式不相邻。
\begin{lstlisting}
`\initcode{Handle infinity and negative zero for NextFloatUp()}{=}`
if (std::isinf(v) && v > 0.)
    return v;
if (v == -0.f)
    v = 0.f;
\end{lstlisting}

概念上，给定一浮点值，我们想对有效数字增加一，
如果结果\keyindex{溢出}{overflow}{}，
则有效数字重置为零且指数增加一。
意外的是对浮点在内存中的整数表示加一实现了这点：
因为指数在有效数字之上的高位，所以如果有效数字全是一，
则有效数字低位加一会将一一路带到指数去，
否则就在当前指数下推进到相邻更大的有效数字。
还要注意当增加最大可表示的有限浮点值数位表示时，
会得到正的浮点无穷数位模式。

对于负值，从数位表示减一类似地推进到相邻值。
\begin{lstlisting}
`\initcode{Advance v to next higher float}{=}`
uint32_t ui = `\refvar{FloatToBits}{}`(v);
if (v >= 0) ++ui;
else        --ui;
return `\refvar{BitsToFloat}{}`(ui);
\end{lstlisting}

这里没有介绍函数\refvar{NextFloatDown}{()}了，
它遵循相同的逻辑但高效地取反。
pbrt也提供了这些函数的{\ttfamily double}版本。

\subsubsection*{算术运算}
IEEE 754提供了关于浮点算术的重要保证：
具体而言，它保证了加法、减法、乘法、除法和平方根
在相同输入下给出相同结果且这些结果的浮点数最接近于
在无限精度算术下执行底层计算的结果
\footnote{IEEE浮点允许用户选一种数字舍入模式，
    但我们这里假设用默认的——舍入到最近的偶数。}。
值得注意的是这在有限精度数字计算机上是完全可能的；
IEEE 754的成就之一是证明了这种级别的精度是可能的且
能在硬件上很高效地实现。

用圆圈运算符表示浮点算术运算符，用sqrt表示浮点平方根，
这些精度保证可以写作：
\begin{align}
    a\oplus b        & =\mathrm{round}(a+b)\, ,\nonumber      \\
    a\ominus b       & =\mathrm{round}(a-b)\, ,\nonumber      \\
    a\otimes b       & =\mathrm{round}(a*b)\, ,\label{eq:3.7} \\
    a\oslash b       & =\mathrm{round}(a/b)\, ,\nonumber      \\
    \mathrm{sqrt}(a) & =\mathrm{round}(\sqrt{a})\, ,\nonumber
\end{align}
其中$\mathrm{round}(x)$表示将实数舍入到最接近的浮点值的结果。

舍入误差的界可以表示为实数区间：例如
对于加法，我们可以说舍入的结果在与某个$\epsilon$有关的区间内
\begin{align}
    a\oplus b & =\mathrm{round}(a+b)\in(a+b)(1\pm\epsilon)\nonumber \\
              & =[(a+b)(1-\epsilon),(a+b)(1+\epsilon)]\, ,
    \label{eq:3.8}
\end{align}
该舍入引入的误差量不超过在$a+b$处的浮点间隔的一半——
如果它超过浮点间隔的一半，则它会以更小误差舍入到另一个不同的浮点数（\reffig{3.41}）。
\begin{figure}[htbp]
    \centering\input{Pictures/chap03/IEEEfloatspacing.tex}
    \caption{IEEE标准规定浮点计算必须实现为假设以无限精度的实数
        执行计算再舍入到最接近的可表示浮点。
        这里，无限精度得到的实数表示为实心点，
        它附近可表示的浮点表示为数轴上的刻度。
        我们可以看到舍入到最近浮点引入的误差$\delta$不超过
        浮点之间间隔的一半。}
    \label{fig:3.41}
\end{figure}

对于32位浮点，我们可以用\refeq{3.6}确定
在$a+b$处的浮点间隔（即该值处的ulp）上界为$(a+b)2^{-23}$，
所以间隔一半的上界为$(a+b)2^{-24}$，所以$|\epsilon|\le2^{-24}$。
该界称为\keyindex{机器$\epsilon$}{machine epsilon}{}
\footnote{不幸的是，C和C++标准用它们自己的特殊方式定义了机器$\epsilon$，
    即数字1之上一个ulp的大小。对于32位浮点，该值为$2^{-23}$，
    是数值分析用的术语机器$\epsilon$的两倍大。}。
对于32位浮点，$\epsilon_{\mathrm{m}}=2^{-24}\approx5.960464\times10^{-8}$。
\begin{lstlisting}
`\refcode{Global Constants}{+=}\lastnext{GlobalConstants}`
static constexpr `\refvar{Float}{}` `\initvar{MachineEpsilon}{}` =
       std::numeric_limits<`\refvar{Float}{}`>::epsilon() * 0.5;
\end{lstlisting}
因此我们有
\begin{align*}
    a\oplus b & =\mathrm{round}(a+b)\in(a+b)(1\pm\epsilon_{\mathrm{m}})\nonumber     \\
              & =[(a+b)(1-\epsilon_{\mathrm{m}}),(a+b)(1+\epsilon_{\mathrm{m}})]\, ,
\end{align*}

类似的关系对其他算术运算符和平方根运算符成立
\footnote{该界假设计算中没有上溢或\protect\keyindex{下溢}{underflow}{}；
    可以很容易处理这些可能的情况\citep[p.56]{doi:10.1137/1.9780898718027}但
    一般对于我们这里的应用并不重要。}。

可以从\refeq{3.7}直接得到许多有用的性质。
对于浮点数$x$，
\begin{itemize}
    \item $1\otimes x=x$。
    \item $x\oslash x=1$。
    \item $x\oplus 0=x$。
    \item $x\ominus x=0$。
    \item $2\otimes x$和$x\oslash 2$是准确的；计算最终结果没有执行舍入。
          更一般地，任何乘以或除以二的幂都得到准确结果（假设没有上溢或下溢）。
    \item $x\oslash 2^i=x\otimes 2^{-i}$对所有整数$i$成立，假设$2^i$不溢出。
\end{itemize}

所有这些性质都是从结果必须是与实际结果最接近的浮点值这一原则推出的；
当结果可以准确表示时，必须算得准确结果。

\subsubsection*{误差传播}
利用IEEE浮点算术的保证，可以开发方法分析并界定给定浮点计算的误差。

\begin{lstlisting}
`\refcode{Global Inline Functions}{+=}\lastnext{GlobalInlineFunctions}`
inline constexpr `\refvar{Float}{}` `\initvar{gamma}{}`(int n) {
    return (n * `\refvar{MachineEpsilon}{}`) / (1 - n * `\refvar{MachineEpsilon}{}`);
}
\end{lstlisting}

\subsubsection*{运行误差分析}
\begin{lstlisting}
`\initcode{EFloat Public Methods}{=}\initnext{EFloatPublicMethods}`
`\initvar{EFloat}{}`() { }
`\refvar{EFloat}{}`(float v, float err = 0.f) : `\refvar[EFloat::v]{v}{}`(v), `\refvar[EFloat::err]{err}{}`(err) {
    `\refcode{Store high-precision reference value in EFloat}{}`
}
\end{lstlisting}

\begin{lstlisting}
`\initcode{EFloat Private Data}{=}\initnext{EFloatPrivateData}`
float `\initvar[EFloat::v]{v}{}`;
float `\initvar[EFloat::err]{err}{}`;
\end{lstlisting}

\begin{lstlisting}
`\refcode{EFloat Private Data}{+=}\lastcode{EFloatPrivateData}`
#ifndef NDEBUG
long double `\initvar[EFloat::ld]{ld}{}`;
#endif // NDEBUG
\end{lstlisting}

\begin{lstlisting}
`\refcode{EFloat Public Methods}{+=}\lastnext{EFloatPublicMethods}`
float `\initvar{UpperBound}{}`() const { return `\refvar{NextFloatUp}{}`(`\refvar[EFloat::v]{v}{}` + `\refvar[EFloat::err]{err}{}`); }
float `\initvar{LowerBound}{}`() const { return `\refvar{NextFloatDown}{}`(`\refvar[EFloat::v]{v}{}` - `\refvar[EFloat::err]{err}{}`); }
\end{lstlisting}

\subsection{稳定的三角形相交}\label{sub:稳定的三角形相交}

\subsection{定界交点误差}\label{sub:定界交点误差}